import streamlit as st
import os
from langchain_community.document_loaders import TextLoader 
from langchain.text_splitter import CharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ====================================================
# 0. è¨­å®šã¨åˆæœŸåŒ– (APIã‚­ãƒ¼ã®ç§˜åŒ¿åŒ–)
# ====================================================
if "GEMINI_API_KEY" in st.secrets:
    os.environ["GOOGLE_API_KEY"] = st.secrets["GEMINI_API_KEY"]
else:
    st.error("ã‚¨ãƒ©ãƒ¼: Secretsã« 'GEMINI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop() 

KNOWLEDGE_BASE_PATH = "knowledge_base.txt" 
PERSIST_DIR = "chroma_db_cache"            

st.set_page_config(page_title="è¦ä»¶äº‹å®Ÿæ”¯æ´ã‚¢ãƒ—ãƒª", layout="wide")

# ====================================================
# 1. RAGã®ã€Œæœ¬æ£šã€æ§‹ç¯‰æ©Ÿèƒ½ï¼ˆå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ°¸ç¶šåŒ–ä»˜ãï¼‰
# ====================================================
@st.cache_resource
def initialize_knowledge_base():
    """çŸ¥è­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆæœ¬æ£šï¼‰ã‚’åˆæœŸåŒ–ã—ã€ChromaDBã‚’è¿”ã™"""
    
    if os.path.exists(PERSIST_DIR):
        try:
            embeddings_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
            db = Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings_model)
            return db
        except Exception as e:
            st.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å†æ§‹ç¯‰ã‚’è©¦ã¿ã¾ã™: {e}")
    
    try:
        loader = TextLoader(KNOWLEDGE_BASE_PATH, encoding="utf-8")
        all_documents = loader.load()
    except FileNotFoundError:
        return None 

    try:
        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
        texts = text_splitter.split_documents(all_documents)
        
        embeddings_model = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            request_options={"timeout": 180}
        )

        db = Chroma.from_documents(
            texts, 
            embeddings_model, 
            persist_directory=PERSIST_DIR
        )
        db.persist()
        return db
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# ====================================================
# 1.5. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£æ©Ÿèƒ½
# ====================================================

@st.cache_data(ttl=600)
def check_query_relevance(query):
    """å…¥åŠ›ã•ã‚ŒãŸã‚¯ã‚¨ãƒªãŒæ³•å¾‹é–¢é€£ã®äº‹æ¡ˆã§ã‚ã‚‹ã‹ã‚’AIã«åˆ¤å®šã•ã›ã‚‹ (ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«)"""
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.0) 
    prompt = f"""
    ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¯ã€**æ³•çš„ãªç´›äº‰ã‚„ä¸»å¼µ**ã«é–¢é€£ã™ã‚‹ã€Œäº‹æ¡ˆã®è¨˜è¿°ã€ã§ã™ã‹ï¼Ÿ
    å…¨ãé–¢ä¿‚ã®ãªã„é›‘è«‡ã€ãƒ¬ã‚·ãƒ”ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã€ã¾ãŸã¯æ„å‘³ã®ãªã„ãƒ©ãƒ³ãƒ€ãƒ ãªæ–‡å­—åˆ—ã§ã‚ã‚‹å ´åˆã¯ã€ŒNoã€ã¨ã ã‘å›ç­”ã—ã¦ãã ã•ã„ã€‚
    ãã‚Œä»¥å¤–ã®å ´åˆã¯ã€ŒYesã€ã¨ã ã‘å›ç­”ã—ã¦ãã ã•ã„ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼š"{query}"
    """
    try:
        response = llm.invoke(prompt)
        return response.content.strip().upper()
    except Exception as e:
        st.warning(f"ã‚¯ã‚¨ãƒªé–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚è©³ç´°: {e}")
        return "YES" 

def check_for_missing_facts(db, query): # ğŸ‘ˆ db ã‚’å¼•æ•°ã«è¿½åŠ 
    """è¦ä»¶äº‹å®Ÿã®ä½œæˆã«è¶³ã‚Šãªã„äº‹å®ŸãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã€è¶³ã‚Šãªã„äº‹å®Ÿã‚’è¿”ã™ (ã‚¹ãƒ†ãƒƒãƒ—2: äº‹å®Ÿè£œå®Œ)"""
    
    # --- RAGæ¤œç´¢ã‚’å®Ÿè¡Œã—ã€å°‚é–€çŸ¥è­˜ã«åŸºã¥ã„ã¦ãƒã‚§ãƒƒã‚¯ã™ã‚‹ ---
    docs = db.similarity_search(query, k=3) 
    context = "\n".join([d.page_content for d in docs])

    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.1)
    
    prompt = f"""
    ã‚ãªãŸã¯è¦ä»¶äº‹å®Ÿè«–ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ã€Œäº‹æ¡ˆã€ã¨ã€Œå‚ç…§æƒ…å ±ã€ã‚’èª­ã¿ã€ã“ã®äº‹æ¡ˆã«åŸºã¥ã„ã¦è¦ä»¶äº‹å®Ÿã‚’ä½œæˆã™ã‚‹å ´åˆã€**æ±ºå®šçš„ã«ä¸è¶³ã—ã¦ã„ã‚‹äº‹å®Ÿ**ã¾ãŸã¯**æ›–æ˜§ãªäº‹å®Ÿ**ã‚’ç‰¹å®šã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è£œå®Œã‚’ä¿ƒã™æ–‡ç« ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    ä¸è¶³ã—ã¦ã„ã‚‹äº‹å®ŸãŒãªã„å ´åˆã¯ã€**å¿…ãš**ã€ŒOKã€ã¨ã ã‘å›ç­”ã—ã¦ãã ã•ã„ã€‚
    
    ã€äº‹æ¡ˆã€‘
    {query}
    
    ã€å‚ç…§æƒ…å ±ã€‘
    {context}
    
    ã€å›ç­”ã®ä¾‹ã€‘
    ãƒ»ä¸è¶³ã—ã¦ã„ã‚‹äº‹å®Ÿï¼šåŸå‘ŠãŒæå®³ã‚’å—ã‘ãŸå…·ä½“çš„ãªé‡‘é¡ã‚’è¿½è¨˜ã—ã¦ãã ã•ã„ã€‚
    ãƒ»OK
    """
    try:
        response = llm.invoke(prompt)
        return response.content.strip()
    except Exception as e:
        st.error(f"äº‹å®Ÿè£œå®Œãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
        return "OK" # ãƒã‚§ãƒƒã‚¯å¤±æ•—æ™‚ã¯å®‰å…¨ã®ãŸã‚å®Ÿè¡Œã‚’è¨±å¯

# RAGã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ (æœ€çµ‚ç”Ÿæˆ - ã‚¹ãƒ†ãƒƒãƒ—3)
def get_required_elements_from_rag(db, description): 
    """RAGã‚’å®Ÿè¡Œã—ã€äº‹æ¡ˆã«å¯¾ã™ã‚‹è¦ä»¶äº‹å®Ÿã®æ§‹æˆã‚’è¿”ã™"""
    
    docs = db.similarity_search(description, k=3) 
    context = "\n".join([d.page_content for d in docs])

    prompt_template = ChatPromptTemplate.from_messages(
        [
            ("system", """
            ã‚ãªãŸã¯è¦ä»¶äº‹å®Ÿè«–ã®å°‚é–€å®¶AIã§ã™ã€‚æ³•çš„æ­£ç¢ºæ€§ã‚’æœ€å„ªå…ˆã—ã¦ãã ã•ã„ã€‚æä¾›ã•ã‚ŒãŸäº‹æ¡ˆã¨å‚ç…§æƒ…å ±ã«åŸºã¥ã„ã¦ã€ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
            ã€ã‚¿ã‚¹ã‚¯ã€‘1. è«‹æ±‚ã®è¶£æ—¨ã‚’ç‰¹å®šã™ã‚‹ã€‚2. æœ€ã‚‚é©åˆ‡ãªè¨´è¨Ÿç‰©ï¼ˆè«‹æ±‚æ¨©ï¼‰ã‚’ç‰¹å®šã™ã‚‹ã€‚3. ãã®è¨´è¨Ÿç‰©ã«å¿…è¦ãªè¦ä»¶äº‹å®Ÿã‚’æ˜ç¢ºãªç®‡æ¡æ›¸ãã§æŠ½å‡ºãƒ»ä½œæˆã™ã‚‹ã€‚4. æŠ—å¼ã€å†æŠ—å¼ãŒã‚ã‚Œã°ä½œæˆã™ã‚‹ã€‚5. å‚ç…§ã—ãŸæ³•ä»¤ã‚„åˆ¤ä¾‹ã‚’æœ€å¾Œã«æ˜è¨˜ã™ã‚‹ã€‚
            """),
            ("user", "ä»¥ä¸‹ã®äº‹æ¡ˆã«ã¤ã„ã¦ã€å¿…è¦ãªè¦ä»¶äº‹å®Ÿã‚’è‡ªå‹•ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\näº‹æ¡ˆ:\n{contract_description}\n\nå‚ç…§æƒ…å ±:\n{context}"),
        ]
    )

    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.1)
    
    chain = prompt_template | llm | StrOutputParser()
    response = chain.invoke({"contract_description": description, "context": context})
    return response

# ====================================================
# 2. Streamlitã®ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªç”»é¢æ§‹ç¯‰
# ====================================================

# --- ã‚¢ãƒ—ãƒªã®çŠ¶æ…‹ç®¡ç† ---
if 'current_step' not in st.session_state:
    st.session_state['current_step'] = 1  # 1: äº‹æ¡ˆå…¥åŠ›, 2: äº‹å®Ÿè£œå®Œå¾…ã¡

st.title("âš–ï¸ è¦ä»¶äº‹å®Ÿ è‡ªå‹•ä½œæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ (RAG-POC)")

# --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã®ãƒ­ã‚¸ãƒƒã‚¯ (ã‚µã‚¤ãƒ‰ãƒãƒ¼) ---
def clear_knowledge_cache():
    st.cache_resource.clear()
    st.rerun()

with st.sidebar:
    st.markdown("### ğŸ› ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†")
    if st.button("çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’å†æ§‹ç¯‰/ãƒªãƒ­ãƒ¼ãƒ‰", help="knowledge_base.txt ã‚’å¤‰æ›´ã—ãŸå¾Œã«æŠ¼ã—ã¦ãã ã•ã„ã€‚", key="reload_db_sidebar"):
        clear_knowledge_cache()
    st.markdown("---")
    if 'fact_feedback' in st.session_state:
        st.markdown("#### ğŸ”„ ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
        st.markdown(f"**äº‹æ¡ˆ:** `{st.session_state['original_query'][:30]}...`")
        st.warning("äº‹å®Ÿè£œå®Œã‚¹ãƒ†ãƒƒãƒ—ã§å¾…æ©Ÿä¸­ã§ã™ã€‚")


# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
db_instance = initialize_knowledge_base()
    
if db_instance:
    # ä¹±ç”¨é˜²æ­¢ãƒ­ã‚¸ãƒƒã‚¯ã®åˆæœŸåŒ–
    if 'running' not in st.session_state:
        st.session_state['running'] = False 
    is_running = st.session_state['running']

    # ----------------------------------------------------
    # ãƒ•ã‚§ãƒ¼ã‚ºè¡¨ç¤º
    # ----------------------------------------------------
    if st.session_state['current_step'] == 1:
        st.info("ã‚¹ãƒ†ãƒƒãƒ— 1/3: äº‹æ¡ˆã®æ¦‚è¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif st.session_state['current_step'] == 2:
        st.info("ã‚¹ãƒ†ãƒƒãƒ— 2/3: ä¸è¶³äº‹å®Ÿã‚’è¿½è¨˜ã¾ãŸã¯ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
    elif st.session_state['current_step'] == 3:
        st.success("ã‚¹ãƒ†ãƒƒãƒ— 3/3: è¦ä»¶äº‹å®Ÿã®æœ€çµ‚æ§‹æˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")


    # ----------------------------------------------------
    # ãƒ¡ã‚¤ãƒ³å…¥åŠ›ã‚¨ãƒªã‚¢ (ã‚¹ãƒ†ãƒƒãƒ— 1 & 2)
    # ----------------------------------------------------
    
    # ã‚¹ãƒ†ãƒƒãƒ—2ã®å ´åˆã€ä»¥å‰ã®ã‚¯ã‚¨ãƒªã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«è¡¨ç¤º
    initial_query = st.session_state.get('original_query', "")
    if st.session_state['current_step'] == 2:
        st.subheader("ğŸ’¡ AIã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
        st.warning(f"{st.session_state['fact_feedback']}")
        initial_query = st.text_area(
            "ã€ä¸è¶³äº‹å®Ÿã‚’è¿½è¨˜ãƒ»ä¿®æ­£ã—ã¦ãã ã•ã„ã€‘",
            value=st.session_state['fact_feedback'] + "\n\n--- ä¿®æ­£ç‚¹ ---",
            height=350,
            key="corrected_query"
        )
    else:
        initial_query = st.text_area(
            "ã€äº‹æ¡ˆã®æ¦‚è¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‘",
            height=300,
            placeholder="ä¾‹ï¼š\nä»¤å’Œ6å¹´5æœˆ1æ—¥ã€å£²ä¸»Aã¯è²·ä¸»Bã«å¯¾ã—ã€ãƒãƒ³ã‚·ãƒ§ãƒ³ã®ä¸€å®¤ã‚’å¼•ãæ¸¡ã—ãŸã€‚\nåŒå¹´5æœˆ10æ—¥ã€Bã¯ã€å¥‘ç´„æ›¸ã«ã€Œå…¨å®¤ç„¡å¢æãƒ•ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã€ã¨ã‚ã‚‹ã«ã‚‚é–¢ã‚ã‚‰ãšã€ãƒªãƒ“ãƒ³ã‚°ã®åºŠæãŒåˆæ¿ã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ãŸãŸã‚ã€å¥‘ç´„ä¸é©åˆã«ã‚ˆã‚‹æå®³è³ å„Ÿã‚’è«‹æ±‚ã—ãŸã„ã€‚",
            key="initial_query"
        )
    
    # ----------------------------------------------------
    # ãƒœã‚¿ãƒ³ã¨ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè¡Œ
    # ----------------------------------------------------
    button_label = "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸ (äº‹å®Ÿç¢ºèª)" if st.session_state['current_step'] != 3 else "ğŸ“ è¦ä»¶äº‹å®Ÿã‚’æœ€çµ‚ç”Ÿæˆã™ã‚‹"

    if st.button(button_label, type="primary", disabled=is_running): 
        if not initial_query:
            st.warning("äº‹æ¡ˆã®æ¦‚è¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            st.session_state['running'] = False # ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãƒ•ãƒ©ã‚°ã‚’ç¢ºå®Ÿã«è§£é™¤
            st.rerun()

        # Phase 1: ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯
        if st.session_state['current_step'] == 1:
            st.session_state['running'] = True
            with st.spinner("ã‚¹ãƒ†ãƒƒãƒ—1/3: æ³•å¾‹é–¢é€£ã®äº‹æ¡ˆã‹ãƒã‚§ãƒƒã‚¯ä¸­ã§ã™..."):
                relevance = check_query_relevance(initial_query)

            if relevance == "NO":
                st.error("å…¥åŠ›å†…å®¹ã¯æ³•å¾‹é–¢é€£ã®äº‹æ¡ˆã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚è¦ä»¶äº‹å®Ÿã«é–¢ã™ã‚‹å…·ä½“çš„ãªäº‹æ¡ˆã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚")
                st.session_state['running'] = False
                st.rerun()
            else:
                # æ³•å¾‹é–¢é€£ã¨åˆ¤æ–­ -> Phase 2: äº‹å®Ÿè£œå®Œãƒã‚§ãƒƒã‚¯ã¸
                st.session_state['original_query'] = initial_query
                st.session_state['running'] = True
                with st.spinner("ã‚¹ãƒ†ãƒƒãƒ—2/3: ä¸è¶³äº‹å®Ÿã®ãƒã‚§ãƒƒã‚¯ä¸­ã§ã™..."):
                    # ğŸ‘ˆ check_for_missing_facts ã« db ã‚’æ¸¡ã™ã‚ˆã†ã«ä¿®æ­£
                    missing_facts = check_for_missing_facts(db_instance, initial_query) 
                
                st.session_state['running'] = False
                
                if "OK" in missing_facts.upper():
                    # ä¸è¶³äº‹å®Ÿãªã— -> Phase 3ã¸ã‚¹ã‚­ãƒƒãƒ—
                    st.session_state['current_step'] = 3
                else:
                    # ä¸è¶³äº‹å®Ÿã‚ã‚Š -> Phase 2ã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å¾…ã¡
                    st.session_state['current_step'] = 2
                    st.session_state['fact_feedback'] = missing_facts
            st.rerun() # ç”»é¢ã‚’æ›´æ–°ã—ã¦æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸

        # Phase 2: äº‹å®Ÿè£œå®Œå¾Œã®æœ€çµ‚å®Ÿè¡Œ (ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰ Phase 3ã¸)
        elif st.session_state['current_step'] == 2:
            st.session_state['current_step'] = 3
            st.session_state['original_query'] = initial_query # ä¿®æ­£ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’ä¿å­˜
            del st.session_state['fact_feedback']
            st.rerun()

        # Phase 3: æœ€çµ‚ç”Ÿæˆ
        elif st.session_state['current_step'] == 3:
            st.session_state['running'] = True
            with st.spinner("ã‚¹ãƒ†ãƒƒãƒ—3/3: è¦ä»¶äº‹å®Ÿã®æœ€çµ‚æ§‹æˆã‚’ç”Ÿæˆä¸­ã§ã™..."):
                try:
                    result = get_required_elements_from_rag(db_instance, initial_query)
                    
                    st.subheader("âœ… è«‹æ±‚æ¨©ã¨è¦ä»¶äº‹å®Ÿã®æ§‹æˆ")
                    st.markdown(result)
                    
                except Exception as e:
                    st.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
                finally:
                    st.session_state['running'] = False
                    st.session_state['current_step'] = 1 # å‡¦ç†å®Œäº†å¾Œã€ã‚¹ãƒ†ãƒƒãƒ—1ã«æˆ»ã™


else:
    # å¤±æ•—æ™‚ã®ã¿ã€è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ« '{KNOWLEDGE_BASE_PATH}' ã®å­˜åœ¨ã¨ä¸­èº«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
