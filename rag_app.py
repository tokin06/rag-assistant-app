import streamlit as st
import os
import uuid
from langchain.text_splitter import RecursiveCharacterTextSplitter 
from langchain_community.document_loaders import TextLoader 
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ====================================================
# 0. è¨­å®šã¨åˆæœŸåŒ– (APIã‚­ãƒ¼ã®ç§˜åŒ¿åŒ–)
# ====================================================
# â˜…â˜…â˜… APIã‚­ãƒ¼ã‚’st.secretsã‹ã‚‰å®‰å…¨ã«å–å¾—ã—ã¾ã™ â˜…â˜…â˜…
if "GEMINI_API_KEY" in st.secrets:
    os.environ["GOOGLE_API_KEY"] = st.secrets["GEMINI_API_KEY"]
else:
    # ç§˜åŒ¿åŒ–ã•ã‚ŒãŸã‚­ãƒ¼ãŒãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã§åœæ­¢
    st.error("ã‚¨ãƒ©ãƒ¼: Secretsã« 'GEMINI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop() 

KNOWLEDGE_BASE_PATH = "knowledge_base.txt" 
PERSIST_DIR = "chroma_db_cache" 
# ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£1: ãƒªã‚½ãƒ¼ã‚¹ä¹±ç”¨å¯¾ç­–ã€‘å…¥åŠ›ã®æœ€å¤§æ–‡å­—æ•°ã‚’è¨­å®š
MAX_INPUT_LENGTH = 3500 # 3500æ–‡å­—ã«åˆ¶é™ (å¿…è¦ã«å¿œã˜ã¦èª¿æ•´å¯èƒ½)

st.set_page_config(page_title="è¦ä»¶äº‹å®Ÿæ”¯æ´ã‚¢ãƒ—ãƒª", layout="wide")

# --- ã‚«ã‚¹ã‚¿ãƒ CSS (è¦–èªæ€§å‘ä¸Š) ã®å†å®šç¾© ---
st.markdown(
    """
    <style>
    /* å…¨ä½“è¨­å®š: ãƒ•ã‚©ãƒ³ãƒˆã‚’èª­ã¿ã‚„ã™ã */
    .stApp {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    
    /* ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ« (H1) ã®è¦–è¦šçš„åŒºåˆ‡ã‚Š */
    h1 {
        color: #333333; /* è½ã¡ç€ã„ãŸãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼ */
        border-bottom: 3px solid #0078D4; /* Microsoftç³»ã®çˆ½ã‚„ã‹ãªé’ç·š */
        padding-bottom: 5px;
    }

    /* æƒ…å ±ãƒœãƒƒã‚¯ã‚¹ (st.info) ã®ãƒ‡ã‚¶ã‚¤ãƒ³ */
    .stAlert {
        border-radius: 8px;
        box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.1);
    }

    /* ãƒ—ãƒ©ã‚¤ãƒãƒªãƒœã‚¿ãƒ³ (æœ€çµ‚ç”Ÿæˆãƒœã‚¿ãƒ³) ã®è¨­å®š */
    .stButton>button[type="primary"] {
        background-color: #0078D4; /* é®®ã‚„ã‹ãªé’ */
        color: white;
        font-weight: bold;
        border-radius: 6px;
        border: none;
        transition: background-color 0.3s;
    }
    .stButton>button[type="primary"]:hover {
        background-color: #005A9E; 
    }
    
    /* ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒœã‚¿ãƒ³ (æœ€åˆã«æˆ»ã‚‹, å¼·åˆ¶ã‚¹ã‚­ãƒƒãƒ—) ã®èª¿æ•´ */
    .stButton>button:not([type="primary"]) {
        background-color: #f0f0f0;
        color: #333333;
        border: 1px solid #cccccc;
        font-weight: 500;
        border-radius: 6px;
    }

    /* å®Ÿè¡Œçµæœ (subheader) ã®åŒºåˆ‡ã‚Š */
    h2 {
        border-left: 5px solid #0078D4;
        padding-left: 10px;
        margin-top: 25px;
    }
    </style>
    """, 
    unsafe_allow_html=True
)

# ====================================================
# 1. RAGã®ã€Œæœ¬æ£šã€æ§‹ç¯‰æ©Ÿèƒ½ï¼ˆå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ°¸ç¶šåŒ–ä»˜ãï¼‰
# ====================================================
@st.cache_resource
def initialize_knowledge_base():
    """çŸ¥è­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆæœ¬æ£šï¼‰ã‚’åˆæœŸåŒ–ã—ã€ChromaDBã‚’è¿”ã™"""
    
    if os.path.exists(PERSIST_DIR):
        try:
            embeddings_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
            db = Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings_model)
            return db
        except Exception as e:
            st.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å†æ§‹ç¯‰ã‚’è©¦ã¿ã¾ã™: {e}")
    
    try:
        loader = TextLoader(KNOWLEDGE_BASE_PATH, encoding="utf-8")
        all_documents = loader.load()
    except FileNotFoundError:
        return None 

    try:
        # --- ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æœ€é©åŒ– ---
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=5000,          # 5000æ–‡å­— (å®Ÿè³ªç„¡åˆ¶é™)
            chunk_overlap=0,            
            separators=["\n\n", "ã€‚", "ã€", "\n", " ", ""], # å¥èª­ç‚¹ã€æ”¹è¡Œã€ã‚¹ãƒšãƒ¼ã‚¹ã‚’å„ªå…ˆ
            length_function=len,
            is_separator_regex=False
        )
        texts = text_splitter.split_documents(all_documents)
        
        embeddings_model = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            request_options={"timeout": 180}
        )

        db = Chroma.from_documents(
            texts, 
            embeddings_model, 
            persist_directory=PERSIST_DIR
        )
        db.persist()
        return db
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# ====================================================
# 1.5. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£æ©Ÿèƒ½
# ====================================================

# ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£2: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ã€‘
def create_safe_prompt(system_instruction, user_query, context=""):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’æ˜ç¢ºãªãƒ‡ãƒªãƒŸã‚¿ã§å›²ã‚“ã å®‰å…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
    
    # å‚ç…§æƒ…å ±ãŒæä¾›ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’çœç•¥
    context_section = f"""
    ---
    ã€å‚ç…§æƒ…å ±ã€‘
    {context}
    ---
    """ if context else ""
    
    base_prompt = f"""
    {system_instruction}

    {context_section}

    ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸäº‹æ¡ˆã€‘
    ***START_OF_USER_QUERY***
    {user_query}
    ***END_OF_USER_QUERY***
    """
    return base_prompt

@st.cache_data(ttl=600)
def check_query_relevance(query):
    """å…¥åŠ›ã•ã‚ŒãŸã‚¯ã‚¨ãƒªãŒæ³•å¾‹é–¢é€£ã®äº‹æ¡ˆã§ã‚ã‚‹ã‹ã‚’AIã«åˆ¤å®šã•ã›ã‚‹ (ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«)"""
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.0) 
    
    system_instruction = """
    ã‚ãªãŸã¯å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†é¡ã™ã‚‹AIã§ã™ã€‚ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¯ã€**æ³•çš„ãªç´›äº‰ã‚„ä¸»å¼µ**ã«é–¢é€£ã™ã‚‹ã€Œäº‹æ¡ˆã®è¨˜è¿°ã€ã§ã™ã‹ï¼Ÿ
    å…¨ãé–¢ä¿‚ã®ãªã„é›‘è«‡ã€ãƒ¬ã‚·ãƒ”ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã€ã¾ãŸã¯æ„å‘³ã®ãªã„ãƒ©ãƒ³ãƒ€ãƒ ãªæ–‡å­—åˆ—ã§ã‚ã‚‹å ´åˆã¯ã€ŒNoã€ã¨ã ã‘å›ç­”ã—ã¦ãã ã•ã„ã€‚
    ãã‚Œä»¥å¤–ã®å ´åˆã¯ã€ŒYesã€ã¨ã ã‘å›ç­”ã—ã¦ãã ã•ã„ã€‚
    å›ç­”ã¯ã€ŒYesã€ã¾ãŸã¯ã€ŒNoã€ã®ã¿ã‚’å³å®ˆã—ã¦ãã ã•ã„ã€‚
    """
    
    prompt = create_safe_prompt(system_instruction, query)
    
    try:
        response = llm.invoke(prompt)
        # LLMã®å‡ºåŠ›ã‹ã‚‰ãƒ‡ãƒªãƒŸã‚¿ã‚’å–ã‚Šé™¤ãå¯èƒ½æ€§ã®ã‚ã‚‹æ–‡å­—ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        return response.content.strip().upper().replace("*", "").replace("`", "")
    except Exception as e:
        st.warning(f"ã‚¯ã‚¨ãƒªé–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚è©³ç´°: {e}")
        return "YES" # ãƒã‚§ãƒƒã‚¯å¤±æ•—æ™‚ã¯å®‰å…¨ã®ãŸã‚å®Ÿè¡Œã‚’è¨±å¯

def check_for_missing_facts(db, query):
    """è¦ä»¶äº‹å®Ÿã®ä½œæˆã«è¶³ã‚Šãªã„äº‹å®ŸãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã€è¶³ã‚Šãªã„äº‹å®Ÿã‚’è¿”ã™ (ã‚¹ãƒ†ãƒƒãƒ—2: äº‹å®Ÿè£œå®Œ)"""
    
    docs = db.similarity_search(query, k=3) 
    context = "\n".join([d.page_content for d in docs])

    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.1)
    
    system_instruction = """
    ã‚ãªãŸã¯è¦ä»¶äº‹å®Ÿã®å°‚é–€å®¶ã§ã™ã€‚æä¾›ã•ã‚ŒãŸå‚ç…§æƒ…å ±ã«åŸºã¥ãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸäº‹æ¡ˆã‚’èª­ã¿ã€ã“ã®äº‹æ¡ˆã«åŸºã¥ã„ã¦è¦ä»¶äº‹å®Ÿã‚’ä½œæˆã™ã‚‹å ´åˆã€**æ±ºå®šçš„ã«ä¸è¶³ã—ã¦ã„ã‚‹ä¸»è¦äº‹å®Ÿ**ã¾ãŸã¯**æ›–æ˜§ãªä¸»è¦äº‹å®Ÿ**ã‚’ç‰¹å®šã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è£œå®Œã‚’ä¿ƒã™æ–‡ç« ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    ä¸è¶³ã—ã¦ã„ã‚‹ä¸»è¦äº‹å®Ÿã€ã‚‚ã—ãã¯æ›–æ˜§ãªä¸»è¦äº‹å®ŸãŒãªã„å ´åˆã¯ã€**å¿…ãš**ã€ŒOKã€ã¨ã ã‘å›ç­”ã—ã¦ãã ã•ã„ã€‚
    è¦ä»¶äº‹å®Ÿã¯ã€é‡è¦ãªé–“æ¥äº‹å®Ÿã«ã¤ã„ã¦ã®æƒ…å ±ã¯ä¸è¦ã§ã™ã‹ã‚‰ã€ä¸»è¦äº‹å®Ÿã ã‘ã«çµã£ã¦æ¤œè¨ã™ã‚‹ã‚ˆã†ã«ãŠé¡˜ã„ã—ã¾ã™ã€‚
    """
    
    prompt = create_safe_prompt(
        system_instruction, 
        query, 
        context
    )
    
    try:
        response = llm.invoke(prompt)
        return response.content.strip()
    except Exception as e:
        st.error(f"äº‹å®Ÿè£œå®Œãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
        return "OK" # ãƒã‚§ãƒƒã‚¯å¤±æ•—æ™‚ã¯å®‰å…¨ã®ãŸã‚å®Ÿè¡Œã‚’è¨±å¯

# RAGã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ (æœ€çµ‚ç”Ÿæˆ - ã‚¹ãƒ†ãƒƒãƒ—3)
def get_required_elements_from_rag(db, description): 
    """RAGã‚’å®Ÿè¡Œã—ã€äº‹æ¡ˆã«å¯¾ã™ã‚‹è¦ä»¶äº‹å®Ÿã®æ§‹æˆã‚’è¿”ã™"""
    
    docs = db.similarity_search(description, k=3) 
    context = "\n".join([d.page_content for d in docs])

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ LangChain ã®å½¢å¼ã§å®‰å…¨ã«å®šç¾©
    prompt_template = ChatPromptTemplate.from_messages(
        [
            ("system", """
            ã‚ãªãŸã¯è¦ä»¶äº‹å®Ÿè«–ã®å°‚é–€å®¶AIã§ã™ã€‚æ³•çš„æ­£ç¢ºæ€§ã‚’æœ€å„ªå…ˆã—ã¦ãã ã•ã„ã€‚æä¾›ã•ã‚ŒãŸå‚ç…§æƒ…å ±ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸäº‹æ¡ˆã€‘ã«åŸºã¥ã„ã¦ã€ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
            ã€ã‚¿ã‚¹ã‚¯ã€‘1. è«‹æ±‚ã®è¶£æ—¨ã‚’ç‰¹å®šã™ã‚‹ã€‚2. æœ€ã‚‚é©åˆ‡ãªè¨´è¨Ÿç‰©ï¼ˆè«‹æ±‚æ¨©ï¼‰ã‚’ç‰¹å®šã™ã‚‹ã€‚3. ãã®è¨´è¨Ÿç‰©ã«å¿…è¦ãªè¦ä»¶äº‹å®Ÿï¼ˆæœ«å°¾ã®ã‚ˆã£ã¦æ›¸ãã‚’å«ã‚€ï¼‰ã‚’æ˜ç¢ºãªç®‡æ¡æ›¸ãã§æŠ½å‡ºãƒ»ä½œæˆã™ã‚‹ã€‚4. æŠ—å¼ã€å†æŠ—å¼ãŒã‚ã‚Œã°ä½œæˆã™ã‚‹ã€‚5. å‚ç…§ã—ãŸæ³•ä»¤ã‚„åˆ¤ä¾‹ã‚’æœ€å¾Œã«æ˜è¨˜ã™ã‚‹ã€‚
            å‚ç…§æƒ…å ±ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š
            {context}
            """),
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¯ãƒ‡ãƒªãƒŸã‚¿ã§å›²ã¾ã‚ŒãŸäº‹æ¡ˆã¨ã—ã¦æ¸¡ã™
            ("user", "ä»¥ä¸‹ã®äº‹æ¡ˆã«ã¤ã„ã¦ã€å¿…è¦ãªè¦ä»¶äº‹å®Ÿã‚’è‡ªå‹•ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸäº‹æ¡ˆã€‘\n***START_OF_USER_QUERY***\n{contract_description}\n***END_OF_USER_QUERY***"),
        ]
    )

    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.1)
    
    chain = prompt_template | llm | StrOutputParser()
    response = chain.invoke({"contract_description": description, "context": context})
    return response

# ====================================================
# 2. Streamlitã®ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªç”»é¢æ§‹ç¯‰
# ====================================================

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°: ã‚¹ãƒ†ãƒƒãƒ—ã‚’ãƒªã‚»ãƒƒãƒˆã—æœ€åˆã«æˆ»ã‚‹ ---
def reset_workflow():
    # Streamlitã®ãƒã‚°å›é¿ã®ãŸã‚ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã€ã‚­ãƒ¼ã‚’å¼·åˆ¶æ›´æ–°
    st.session_state['current_step'] = 1
    
    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«å¿…è¦ãªã‚­ãƒ¼ã‚’å‰Šé™¤
    keys_to_delete = ['original_query', 'edited_query_for_step2', 'initial_query', 'fact_feedback', 'running']
    for key in keys_to_delete:
        if key in st.session_state:
            del st.session_state[key]
    
    # å…¥åŠ›ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®ã‚­ãƒ¼ã‚’æ›´æ–°ã—ã€æ–°ã—ã„ç©ºã®ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’å¼·åˆ¶æç”»ã•ã›ã‚‹
    st.session_state['input_key'] = str(uuid.uuid4())
    
    st.rerun() 

# --- ã‚¢ãƒ—ãƒªã®çŠ¶æ…‹ç®¡ç† ---
if 'current_step' not in st.session_state:
    st.session_state['current_step'] = 1 
if 'original_query' not in st.session_state:
    st.session_state['original_query'] = "" # å…¨ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å‚ç…§ã™ã‚‹ã€ŒçœŸå®Ÿã®æºã€ã‚’åˆæœŸåŒ–
if 'input_key' not in st.session_state:
    st.session_state['input_key'] = str(uuid.uuid4()) # å…¥åŠ›ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®ã‚­ãƒ¼ã‚’åˆæœŸåŒ–

st.title("âš–ï¸ è¦ä»¶äº‹å®Ÿ è‡ªå‹•ä½œæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")


# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
db_instance = initialize_knowledge_base()
    
if db_instance:
    # ä¹±ç”¨é˜²æ­¢ãƒ­ã‚¸ãƒƒã‚¯ã®åˆæœŸåŒ–
    if 'running' not in st.session_state:
        st.session_state['running'] = False 
    is_running = st.session_state['running']

    # ----------------------------------------------------
    # ãƒ•ã‚§ãƒ¼ã‚ºè¡¨ç¤º
    # ----------------------------------------------------
    if st.session_state['current_step'] == 1:
        st.info("ã‚¹ãƒ†ãƒƒãƒ— 1/3: äº‹æ¡ˆã®æ¦‚è¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif st.session_state['current_step'] == 2:
        st.info("ã‚¹ãƒ†ãƒƒãƒ— 2/3: ä¸è¶³äº‹å®Ÿã‚’è¿½è¨˜ã¾ãŸã¯ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
    elif st.session_state['current_step'] == 3:
        st.success("ã‚¹ãƒ†ãƒƒãƒ— 3/3: è¦ä»¶äº‹å®Ÿã®æœ€çµ‚æ§‹æˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚")


    # ----------------------------------------------------
    # ãƒ¡ã‚¤ãƒ³å…¥åŠ›ã‚¨ãƒªã‚¢ (ã‚¹ãƒ†ãƒƒãƒ— 1 & 2 & 3)
    # ----------------------------------------------------
    
    original_query = st.session_state.get('original_query', "")
    
    if st.session_state['current_step'] == 2:
        # ã‚¹ãƒ†ãƒƒãƒ—2ã®å…¥åŠ›ã‚¨ãƒªã‚¢
        st.subheader("ğŸ’¡ AIã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
        st.warning(f"ä»¥ä¸‹ã®ä¸è¶³äº‹å®Ÿã‚’è¿½è¨˜ãƒ»ä¿®æ­£ã—ã¦ãã ã•ã„:\n\n{st.session_state['fact_feedback']}")
        
        # ä»¥å‰ã®ã‚¯ã‚¨ãƒªã‚’ç·¨é›†å¯èƒ½ãªãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«è¡¨ç¤º
        edited_query = st.text_area(
            "ã€ä¸è¶³äº‹å®Ÿã‚’è¿½è¨˜ãƒ»ä¿®æ­£ã—ã¦ãã ã•ã„ã€‘",
            value=original_query, # original_query ã®æœ€æ–°å€¤ã‚’è¡¨ç¤º
            height=350,
            key="edited_query_for_step2", # ã‚¹ãƒ†ãƒƒãƒ—2å°‚ç”¨ã®ã‚­ãƒ¼
            max_chars=MAX_INPUT_LENGTH # ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£1: ãƒªã‚½ãƒ¼ã‚¹ä¹±ç”¨å¯¾ç­–ã€‘
        )

    else:
        # ã‚¹ãƒ†ãƒƒãƒ—1ã¨3ã®å…¥åŠ›ã‚¨ãƒªã‚¢
        current_query = st.text_area(
            "ã€äº‹æ¡ˆã®æ¦‚è¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‘",
            value=original_query, # original_query ã®å€¤ã‚’è¡¨ç¤º
            height=300,
            placeholder=f"ä¾‹ï¼š\nï¼¸ã®è¨€ã„åˆ†\nç§ã¯ã€ä»¤å’Œï¼–å¹´ï¼”æœˆï¼–æ—¥ã«ã€çˆ¶ï¼¡ã‹ã‚‰ç›¸ç¶šã—ã¦ç§ãŒæ‰€æœ‰ã—ã¦ã„ãŸç”²åœŸåœ°ã‚’ã€æ˜¯éæ¬²ã—ã„ã¨è¨€ã£ã¦ããŸå‹äººã®ï¼¹ã«å£²ã‚Šã¾ã—ãŸã€‚ä»£é‡‘ã¯ï¼’ï¼ï¼ï¼ä¸‡å††ã§ã€æ”¯æ‰•æ—¥ã¯ä»¤å’Œï¼–å¹´ï¼•æœˆï¼–æ—¥ã®ç´„æŸã§ã€åŒå¹´ï¼”æœˆï¼–æ—¥ã«ï¼¹ã«ç”²åœŸåœ°ã‚’å¼•ãæ¸¡ã—ã¾ã—ãŸã€‚ã¨ã“ã‚ãŒã€ï¼¹ã¯ã€ã„ã‚ã„ã‚ã¨æ–‡å¥ã‚’è¨€ã£ã¦ãã®ä»£é‡‘ã‚’æ”¯æ‰•ã£ã¦ãã‚Œã¾ã›ã‚“ã€‚ãã“ã§ã€ä¸Šè¨˜å£²è²·å¥‘ç´„ã«åŸºã¥ã„ã¦ä»£é‡‘ï¼’ï¼ï¼ï¼ä¸‡å††ã®æ”¯æ‰•ã‚’æ±‚ã‚ã¾ã™ã€‚\n\nï¼¹ã®è¨€ã„åˆ†\nç”²åœŸåœ°ã‚’å£²è²·ã™ã‚‹ã“ã¨ã«ã¤ã„ã¦ã¯ç§ã‚‚ï¼¸ã‚‚ç•°è«–ãŒãªã‹ã£ãŸã®ã§ã™ãŒã€çµå±€ã€ä»£é‡‘é¡ã«ã¤ã„ã¦æŠ˜ã‚Šåˆã„ãŒã¤ãã¾ã›ã‚“ã§ã—ãŸã€‚ç”²åœŸåœ°ã¯ã€ï¼¸ãŒç›¸ç¶šã§å–å¾—ã—ãŸã®ã§ã¯ãªãã€ï¼¸ã®å”çˆ¶ï¼¢ã‹ã‚‰è´ˆä¸ã•ã‚ŒãŸã‚‚ã®ã®ã¯ãšã§ã™ã‹ã‚‰ã€ï¼¸ã¯å˜˜ã‚’ã¤ã„ã¦ã„ã¾ã™ã€‚ã€€\n\nï¼ˆæœ€å¤§{MAX_INPUT_LENGTH}æ–‡å­—ï¼‰",
            key=st.session_state['input_key'], # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚­ãƒ¼ã‚’ä½¿ç”¨
            max_chars=MAX_INPUT_LENGTH # ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£1: ãƒªã‚½ãƒ¼ã‚¹ä¹±ç”¨å¯¾ç­–ã€‘
        )
        # å…¥åŠ›ã•ã‚ŒãŸå€¤ã‚’ original_query ã«ãƒã‚¤ãƒ³ãƒ‰
        st.session_state['original_query'] = current_query  
    
    # ----------------------------------------------------
    # ãƒœã‚¿ãƒ³ã¨ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè¡Œ
    # ----------------------------------------------------
    
    # ãƒœã‚¿ãƒ³é…ç½®: ãƒ¡ã‚¤ãƒ³ãƒœã‚¿ãƒ³ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒœã‚¿ãƒ³ã‚’æ¨ªä¸¦ã³ã«ã™ã‚‹
    col_main, col_reset = st.columns([0.75, 0.25]) 

    # --- 2. æœ€åˆã«æˆ»ã‚‹ãƒœã‚¿ãƒ³ (col_reset) ---
    with col_reset:
        # Step 2 ã®å ´åˆã¯ã€ãƒ¡ã‚¤ãƒ³ãƒœã‚¿ãƒ³ãŒ2ã¤ã‚ã‚‹ãŸã‚é«˜ã•ã‚’èª¿æ•´
        if st.session_state['current_step'] == 2:
             # å¼·åˆ¶ã‚¹ã‚­ãƒƒãƒ—ãƒœã‚¿ãƒ³ã®åˆ†ã ã‘é«˜ã•ã‚’åˆã‚ã›ã‚‹ãŸã‚ã€ã‚¹ãƒšãƒ¼ã‚¹ã¯çŸ­ãã™ã‚‹
             st.markdown("<div style='height: 1px;'></div>", unsafe_allow_html=True) 
        else:
            st.markdown("<div style='height: 35px;'></div>", unsafe_allow_html=True) 
        if st.button("æœ€åˆã«æˆ»ã‚‹", help="ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ã‚¹ãƒ†ãƒƒãƒ—1ã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã€‚", use_container_width=True):
            reset_workflow()
            
    # --- 1. ãƒ¡ã‚¤ãƒ³ãƒœã‚¿ãƒ³ (col_main) ---
    with col_main:
        
        # Step 2: 2ã¤ã®ãƒœã‚¿ãƒ³ã‚’ä¸¦ã¹ã‚‹ (å†ãƒã‚§ãƒƒã‚¯/å¼·åˆ¶ã‚¹ã‚­ãƒƒãƒ—)
        if st.session_state['current_step'] == 2:
            
            st.markdown("---")
            st.subheader("å®Ÿè¡Œã‚ªãƒ—ã‚·ãƒ§ãƒ³")
            
            col_recheck, col_force = st.columns([0.5, 0.5])
            
            # --- ã‚ªãƒ—ã‚·ãƒ§ãƒ³ A: AIã«å†ãƒã‚§ãƒƒã‚¯ã•ã›ã‚‹ (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã®ç¶­æŒ) ---
            with col_recheck:
                if st.button("ä¿®æ­£å†…å®¹ã§å†ãƒã‚§ãƒƒã‚¯ã—ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸", type="primary", disabled=is_running, help="AIãŒä¿®æ­£å¾Œã®äº‹æ¡ˆã‚’å†åº¦ãƒã‚§ãƒƒã‚¯ã—ã€ä¸è¶³äº‹å®ŸãŒãªã„å ´åˆã«æœ€çµ‚ç”Ÿæˆã«é€²ã¿ã¾ã™ã€‚", key="btn_recheck"):
                    
                    # Step 2ã®å…¥åŠ›å€¤ã‚’å–å¾—
                    current_query = st.session_state.get('edited_query_for_step2', st.session_state['original_query'])
                    
                    if not current_query or current_query.strip() == "":
                        st.warning("äº‹æ¡ˆã®æ¦‚è¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                        st.session_state['running'] = False
                        st.rerun()
                    elif len(current_query) > MAX_INPUT_LENGTH:
                        st.error(f"å…¥åŠ›ãŒé•·ã™ãã¾ã™ã€‚{MAX_INPUT_LENGTH}æ–‡å­—ä»¥ä¸‹ã«ã—ã¦ãã ã•ã„ã€‚")
                        st.session_state['running'] = False
                        st.stop()
                        
                    st.session_state['original_query'] = current_query # ä¿®æ­£ã•ã‚ŒãŸæœ€æ–°ã®ã‚¯ã‚¨ãƒªã‚’ä¿å­˜
                    
                    st.session_state['running'] = True
                    with st.spinner("ã‚¹ãƒ†ãƒƒãƒ—2/3: ä¿®æ­£ã•ã‚ŒãŸäº‹æ¡ˆã§ä¸è¶³äº‹å®Ÿã‚’å†ãƒã‚§ãƒƒã‚¯ä¸­ã§ã™..."):
                        missing_facts_recheck = check_for_missing_facts(db_instance, current_query)
                    
                    st.session_state['running'] = False
                    
                    if "OK" in missing_facts_recheck.upper():
                        st.session_state['current_step'] = 3
                        if 'fact_feedback' in st.session_state: del st.session_state['fact_feedback']
                    else:
                        st.session_state['current_step'] = 2
                        st.session_state['fact_feedback'] = missing_facts_recheck 
                        st.error("ã¾ã ä¸è¶³ã—ã¦ã„ã‚‹äº‹å®ŸãŒã‚ã‚Šã¾ã™ã€‚AIã®æŒ‡æ‘˜ã‚’å‚è€ƒã«å†åº¦è¿½è¨˜ã—ã¦ãã ã•ã„ã€‚")

                    st.rerun()
                    
            # --- ã‚ªãƒ—ã‚·ãƒ§ãƒ³ B: å¼·åˆ¶ã‚¹ã‚­ãƒƒãƒ— (ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æœ›ã®æ–°æ©Ÿèƒ½) ---
            with col_force:
                if st.button("ã“ã®æƒ…å ±ã§è¦ä»¶äº‹å®Ÿã‚’æœ€çµ‚ç”Ÿæˆã™ã‚‹ (ä¸è¶³äº‹å®Ÿã‚’ç„¡è¦–)", disabled=is_running, help="AIã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç„¡è¦–ã—ã€ç¾åœ¨ã®äº‹æ¡ˆè¨˜è¿°ã§æœ€çµ‚çš„ãªè¦ä»¶äº‹å®Ÿã®ç”Ÿæˆã«é€²ã¿ã¾ã™ã€‚", key="btn_force_skip"):
                    
                    # Step 2ã®å…¥åŠ›å€¤ã‚’å–å¾—
                    current_query = st.session_state.get('edited_query_for_step2', st.session_state['original_query'])
                    
                    if not current_query or current_query.strip() == "":
                        st.warning("äº‹æ¡ˆã®æ¦‚è¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                        st.session_state['running'] = False
                        st.rerun()
                    elif len(current_query) > MAX_INPUT_LENGTH:
                        st.error(f"å…¥åŠ›ãŒé•·ã™ãã¾ã™ã€‚{MAX_INPUT_LENGTH}æ–‡å­—ä»¥ä¸‹ã«ã—ã¦ãã ã•ã„ã€‚")
                        st.session_state['running'] = False
                        st.stop()
                        
                    # å¼·åˆ¶ã‚¹ã‚­ãƒƒãƒ—æ™‚ã¯ã€ç·¨é›†å¾Œã®ã‚¯ã‚¨ãƒªã‚’ä¿å­˜ã—ã€ã‚¹ãƒ†ãƒƒãƒ—3ã¸
                    st.session_state['original_query'] = current_query 
                    st.session_state['current_step'] = 3
                    if 'fact_feedback' in st.session_state: del st.session_state['fact_feedback']
                    st.rerun()
                    
        
        else: # Step 1 ã¾ãŸã¯ Step 3 ã®å ´åˆ (å˜ä¸€ãƒœã‚¿ãƒ³)
            
            button_label = "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸ (äº‹å®Ÿç¢ºèª)" if st.session_state['current_step'] != 3 else "ğŸ“ è¦ä»¶äº‹å®Ÿã‚’æœ€çµ‚ç”Ÿæˆã™ã‚‹"
            
            # Step 1/3ã®å…¥åŠ›å€¤ (st.session_state['original_query'] ã«ãƒã‚¤ãƒ³ãƒ‰æ¸ˆã¿)
            current_query = st.session_state.get('original_query', "") 

            if st.button(button_label, type="primary", disabled=is_running): 
                
                # å…¥åŠ›é•·ãƒã‚§ãƒƒã‚¯ (Step 1/3 ã®å…¥åŠ›ã‚¨ãƒªã‚¢ã¯ 'original_query' ãŒæœ€æ–°å€¤)
                if not current_query or current_query.strip() == "":
                    st.warning("äº‹æ¡ˆã®æ¦‚è¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                    st.session_state['running'] = False 
                    st.rerun()
                elif len(current_query) > MAX_INPUT_LENGTH:
                    st.error(f"å…¥åŠ›ãŒé•·ã™ãã¾ã™ã€‚{MAX_INPUT_LENGTH}æ–‡å­—ä»¥ä¸‹ã«ã—ã¦ãã ã•ã„ã€‚")
                    st.session_state['running'] = False
                    st.stop() 
                    
                # Phase 1: ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯
                if st.session_state['current_step'] == 1:
                    st.session_state['running'] = True
                    with st.spinner("ã‚¹ãƒ†ãƒƒãƒ—1/3: æ³•å¾‹é–¢é€£ã®äº‹æ¡ˆã‹ãƒã‚§ãƒƒã‚¯ä¸­ã§ã™..."):
                        relevance = check_query_relevance(current_query)

                    if relevance == "NO":
                        st.error("å…¥åŠ›å†…å®¹ã¯æ³•å¾‹é–¢é€£ã®äº‹æ¡ˆã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚è¦ä»¶äº‹å®Ÿã«é–¢ã™ã‚‹å…·ä½“çš„ãªäº‹æ¡ˆã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚")
                        st.session_state['running'] = False
                        st.rerun()
                    else:
                        # æ³•å¾‹é–¢é€£ã¨åˆ¤æ–­ -> Phase 2: äº‹å®Ÿè£œå®Œãƒã‚§ãƒƒã‚¯ã¸
                        st.session_state['original_query'] = current_query 
                        st.session_state['running'] = True
                        with st.spinner("ã‚¹ãƒ†ãƒƒãƒ—2/3: ä¸è¶³äº‹å®Ÿã®ãƒã‚§ãƒƒã‚¯ä¸­ã§ã™..."):
                            missing_facts = check_for_missing_facts(db_instance, current_query) 
                        
                        st.session_state['running'] = False
                        
                        if "OK" in missing_facts.upper():
                            st.session_state['current_step'] = 3
                        else:
                            st.session_state['current_step'] = 2
                            st.session_state['fact_feedback'] = missing_facts
                        st.rerun() 

                # Phase 3: æœ€çµ‚ç”Ÿæˆ
                elif st.session_state['current_step'] == 3:
                    st.session_state['running'] = True
                    with st.spinner("ã‚¹ãƒ†ãƒƒãƒ—3/3: è¦ä»¶äº‹å®Ÿã®æœ€çµ‚æ§‹æˆã‚’ç”Ÿæˆä¸­ã§ã™..."):
                        try:
                            # æœ€çµ‚çš„ã«ä½¿ç”¨ã™ã‚‹ã‚¯ã‚¨ãƒªã¯ st.session_state['original_query']
                            result = get_required_elements_from_rag(db_instance, st.session_state['original_query'])
                            
                            st.subheader("âœ… è«‹æ±‚æ¨©ã¨è¦ä»¶äº‹å®Ÿã®æ§‹æˆ")
                            st.markdown(result)
                            
                        except Exception as e:
                            st.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
                        finally:
                            st.session_state['running'] = False
                            st.session_state['current_step'] = 1 # å‡¦ç†å®Œäº†å¾Œã€ã‚¹ãƒ†ãƒƒãƒ—1ã«æˆ»ã‚‹

else:
    # å¤±æ•—æ™‚ã®ã¿ã€è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ« '{KNOWLEDGE_BASE_PATH}' ã®å­˜åœ¨ã¨ä¸­èº«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
