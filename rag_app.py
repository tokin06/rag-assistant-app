import streamlit as st
import os
from langchain_community.document_loaders import TextLoader 
from langchain.text_splitter import CharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ====================================================
# 0. è¨­å®šã¨åˆæœŸåŒ– (APIã‚­ãƒ¼ã®ç§˜åŒ¿åŒ–)
# ====================================================
if "GEMINI_API_KEY" in st.secrets:
    os.environ["GOOGLE_API_KEY"] = st.secrets["GEMINI_API_KEY"]
else:
    st.error("ã‚¨ãƒ©ãƒ¼: Secretsã« 'GEMINI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop() 

KNOWLEDGE_BASE_PATH = "knowledge_base.txt" 
PERSIST_DIR = "chroma_db_cache"            

st.set_page_config(page_title="è¦ä»¶äº‹å®Ÿæ”¯æ´ã‚¢ãƒ—ãƒª", layout="wide")

# (ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ãƒ­ã‚¸ãƒƒã‚¯ã¯çœç•¥ - Streamlit Cloudã®è¨­å®šã«ä¾å­˜)

# ====================================================
# 1. RAGã®ã€Œæœ¬æ£šã€æ§‹ç¯‰æ©Ÿèƒ½ï¼ˆå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ°¸ç¶šåŒ–ä»˜ãï¼‰
# ====================================================
@st.cache_resource
def initialize_knowledge_base():
    # ... (ã“ã®é–¢æ•°ã¯å¤‰æ›´ãªã—)
    
    # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ (é«˜é€Ÿãƒ­ãƒ¼ãƒ‰)
    if os.path.exists(PERSIST_DIR):
        try:
            embeddings_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
            db = Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings_model)
            return db
        except Exception as e:
            st.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å†æ§‹ç¯‰ã‚’è©¦ã¿ã¾ã™: {e}")
    
    try:
        loader = TextLoader(KNOWLEDGE_BASE_PATH, encoding="utf-8")
        all_documents = loader.load()
    except FileNotFoundError:
        return None 

    try:
        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
        texts = text_splitter.split_documents(all_documents)
        
        embeddings_model = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            request_options={"timeout": 180}
        )

        db = Chroma.from_documents(
            texts, 
            embeddings_model, 
            persist_directory=PERSIST_DIR
        )
        db.persist()
        return db
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# ====================================================
# 1.5. æ–°ã—ã„ä¹±ç”¨é˜²æ­¢ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
# ====================================================

@st.cache_data(ttl=600) # 10åˆ†é–“ã¯åŒã˜ã‚¯ã‚¨ãƒªã®å†ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—
def check_query_relevance(query):
    """å…¥åŠ›ã•ã‚ŒãŸã‚¯ã‚¨ãƒªãŒæ³•å¾‹é–¢é€£ã®äº‹æ¡ˆã§ã‚ã‚‹ã‹ã‚’AIã«åˆ¤å®šã•ã›ã‚‹"""
    
    # ä¹±ç”¨ãƒã‚§ãƒƒã‚¯ç”¨ã®ä½ã‚³ã‚¹ãƒˆãªLLM
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.0) 
    
    # AIã¸ã®æŒ‡ç¤ºï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
    prompt = f"""
    ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¯ã€ä¸å‹•ç”£ã€å¥‘ç´„ã€æå®³è³ å„Ÿã€æ‰€æœ‰æ¨©ã€å®¶æ—æ³•ãªã©ã€**æ³•çš„ãªç´›äº‰ã‚„ä¸»å¼µ**ã«é–¢é€£ã™ã‚‹ã€Œäº‹æ¡ˆã®è¨˜è¿°ã€ã§ã™ã‹ï¼Ÿ
    å…¨ãé–¢ä¿‚ã®ãªã„é›‘è«‡ã€è©©ã€ãƒ¬ã‚·ãƒ”ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã€ã¾ãŸã¯æ„å‘³ã®ãªã„ãƒ©ãƒ³ãƒ€ãƒ ãªæ–‡å­—åˆ—ã§ã‚ã‚‹å ´åˆã¯ã€ŒNoã€ã¨ã ã‘å›ç­”ã—ã¦ãã ã•ã„ã€‚
    ãã‚Œä»¥å¤–ã®å ´åˆã¯ã€ŒYesã€ã¨ã ã‘å›ç­”ã—ã¦ãã ã•ã„ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼š"{query}"
    """
    
    try:
        response = llm.invoke(prompt)
        # å›ç­”ã‹ã‚‰ "Yes" ã¾ãŸã¯ "No" ã®æ–‡å­—åˆ—ã‚’å–å¾—ã—ã€å¤§æ–‡å­—ã«å¤‰æ›ã—ã¦è¿”ã™
        return response.content.strip().upper()
    except Exception as e:
        st.warning(f"ã‚¯ã‚¨ãƒªé–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚è©³ç´°: {e}")
        return "YES" # ãƒã‚§ãƒƒã‚¯å¤±æ•—æ™‚ã¯å®‰å…¨ã®ãŸã‚å®Ÿè¡Œã‚’è¨±å¯

# RAGã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ (å¤‰æ›´ãªã—)
def get_required_elements_from_rag(db, description): 
    # ... (ã“ã®é–¢æ•°ã¯å¤‰æ›´ãªã—)
    docs = db.similarity_search(description, k=3) 
    context = "\n".join([d.page_content for d in docs])

    prompt_template = ChatPromptTemplate.from_messages(
        [
            ("system", """
            ã‚ãªãŸã¯è¦ä»¶äº‹å®Ÿè«–ã®å°‚é–€å®¶AIã§ã™ã€‚è¦ä»¶äº‹å®Ÿã®å‡ºåŠ›ã«ãŠã„ã¦ã¯æ³•çš„æ­£ç¢ºæ€§ã‚’æœ€å„ªå…ˆã—ã¦ãã ã•ã„ã€‚
            æä¾›ã•ã‚ŒãŸã€Œäº‹æ¡ˆã€ã¨ã€å‚ç…§æƒ…å ±ã«åŸºã¥ã„ã¦ã€ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
            
1. äº‹æ¡ˆã‹ã‚‰**è«‹æ±‚ã®è¶£æ—¨**ã‚’ç‰¹å®šã™ã‚‹ã€‚
2. äº‹æ¡ˆã‹ã‚‰**æœ€ã‚‚é©åˆ‡ãªè¨´è¨Ÿç‰©ï¼ˆè«‹æ±‚æ¨©ï¼‰**ã‚’ç‰¹å®šã™ã‚‹ã€‚
3. ãã®è¨´è¨Ÿç‰©ã«å¿…è¦ãª**è¦ä»¶äº‹å®Ÿ**ã‚’ã€**æ˜ç¢ºãªç®‡æ¡æ›¸ã**ã§æŠ½å‡ºãƒ»ä½œæˆã™ã‚‹ã€‚
4. æŠ—å¼ã€å†æŠ—å¼ã€å†ã€…æŠ—å¼ãƒ»ãƒ»ãƒ»ãŒæˆã‚Šç«‹ã¤å ´åˆã¯ã€æˆã‚Šç«‹ã¤æŠ—å¼ã‚’ä½œæˆã™ã‚‹ã€‚ï¼’ã¤ä»¥ä¸Šã®æŠ—å¼ãŒæˆã‚Šç«‹ã¤å ´åˆã¯ã€ãã‚Œãã‚Œã®æŠ—å¼ã«å¯¾ã™ã‚‹å†æŠ—å¼ä»¥ä¸‹ã§ã‚ã‚‹ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ã€å†æŠ—å¼ä»¥ä¸‹ã‚‚ä½œæˆã™ã‚‹ã€‚
5. å‚ç…§ã—ãŸè¦ä»¶äº‹å®Ÿã®æ ¹æ‹ ã¨ãªã‚‹**æ³•ä»¤ã‚„åˆ¤ä¾‹**ãŒã‚ã‚Œã°ã€æœ€å¾Œã«æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚
            """),
            ("user", "ä»¥ä¸‹ã®äº‹æ¡ˆã«ã¤ã„ã¦ã€å¿…è¦ãªè¦ä»¶äº‹å®Ÿã‚’è‡ªå‹•ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\näº‹æ¡ˆ:\n{contract_description}\n\nå‚ç…§æƒ…å ±:\n{context}"),
        ]
    )

    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.1)
    
    chain = prompt_template | llm | StrOutputParser()
    response = chain.invoke({"contract_description": description, "context": context})
    return response

# ====================================================
# 2. Streamlitã®ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªç”»é¢æ§‹ç¯‰
# ====================================================

st.title("âš–ï¸ è¦ä»¶äº‹å®Ÿ è‡ªå‹•ä½œæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ (RAG-POC)")

# --- é–‹ç™ºãƒ•ãƒ©ã‚°ã®å®šç¾© (ãƒ­ã‚°è¡¨ç¤ºã‚’ã‚¯ãƒªãƒ¼ãƒ³ã«ã™ã‚‹ãŸã‚) ---
IS_STREAMLIT_CLOUD = "STREAMLIT_SERVER_USER" in os.environ 

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
db_instance = initialize_knowledge_base()
    
# --- æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®éè¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯ (ã‚¹ãƒãƒ¼ãƒˆè¡¨ç¤º) ---
if db_instance:
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒæ­£å¸¸ã«ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯æ§‹ç¯‰ã•ã‚ŒãŸå ´åˆã€ç”»é¢ã‚’è¡¨ç¤º
    
    # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º (ã‚¹ãƒãƒ¼ãƒˆè¡¨ç¤º)
    if not IS_STREAMLIT_CLOUD:
        # ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚ã«ã®ã¿æˆåŠŸã‚’è­¦å‘Šã¨ã—ã¦è¡¨ç¤º
        st.warning("ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã§ã™ã€‚Webå…¬é–‹æ™‚ã¯ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ãŒã‹ã‹ã‚Šã¾ã™ã€‚")
    # Webå…¬é–‹æ™‚ã¯ st.success ã¯è¡¨ç¤ºã—ãªã„ (ä»£ã‚ã‚Šã« st.info ã‚’ä½¿ç”¨)
    
    st.info("â€»äº‹æ¡ˆã®æ¦‚è¦ï¼ˆã„ã¤ã€èª°ãŒã€ä½•ã‚’ã€ã©ã†ã—ãŸã‹ï¼‰ã‚’è©³ç´°ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    # ... (ä¸­ç•¥ï¼šå…¥åŠ›ã‚¨ãƒªã‚¢)
    contract_description = st.text_area(
        "ã€äº‹æ¡ˆã®æ¦‚è¦ã€‘ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚",
        height=300,
        placeholder="ä¾‹ï¼š\nä»¤å’Œ6å¹´5æœˆ1æ—¥ã€å£²ä¸»Aã¯è²·ä¸»Bã«å¯¾ã—ã€ãƒãƒ³ã‚·ãƒ§ãƒ³ã®ä¸€å®¤ã‚’å¼•ãæ¸¡ã—ãŸã€‚\nåŒå¹´5æœˆ10æ—¥ã€Bã¯ã€å¥‘ç´„æ›¸ã«ã€Œå…¨å®¤ç„¡å¢æãƒ•ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã€ã¨ã‚ã‚‹ã«ã‚‚é–¢ã‚ã‚‰ãšã€ãƒªãƒ“ãƒ³ã‚°ã®åºŠæãŒåˆæ¿ã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ãŸãŸã‚ã€å¥‘ç´„ä¸é©åˆã«ã‚ˆã‚‹æå®³è³ å„Ÿã‚’è«‹æ±‚ã—ãŸã„ã€‚"
    )
    
    # --- ä¹±ç”¨é˜²æ­¢ãƒ­ã‚¸ãƒƒã‚¯ ---
    if 'running' not in st.session_state:
        st.session_state['running'] = False 
    is_running = st.session_state['running']

    if st.button("ğŸ“ è¦ä»¶äº‹å®Ÿã‚’è‡ªå‹•ä½œæˆã™ã‚‹", type="primary", disabled=is_running): 
        if not contract_description:
            st.warning("äº‹æ¡ˆã®æ¦‚è¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            # 1. ä¹±ç”¨é˜²æ­¢ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ
            with st.spinner("å…¥åŠ›å†…å®¹ãŒæ³•å¾‹é–¢é€£ã®äº‹æ¡ˆã‹ãƒã‚§ãƒƒã‚¯ä¸­ã§ã™..."):
                relevance = check_query_relevance(contract_description)

            if relevance == "NO":
                st.error("å…¥åŠ›å†…å®¹ãŒæ³•å¾‹é–¢é€£ã®äº‹æ¡ˆã¨ã—ã¦èªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚è¦ä»¶äº‹å®Ÿã«é–¢ã™ã‚‹å…·ä½“çš„ãªäº‹æ¡ˆã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚")
            else:
                # 2. RAGå‡¦ç†ã®å®Ÿè¡Œ
                st.session_state['running'] = True
                with st.spinner("AIãŒè¦ä»¶äº‹å®Ÿè«–ã¨çŸ¥è­˜ã‚’å‚ç…§ã—ã¦åˆ†æä¸­ã§ã™..."):
                    try:
                        result = get_required_elements_from_rag(db_instance, contract_description)
                        
                        st.subheader("âœ… è«‹æ±‚æ¨©ã¨è¦ä»¶äº‹å®Ÿã®æ§‹æˆ")
                        st.markdown(result)
                        
                    except Exception as e:
                        st.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
                    finally:
                        st.session_state['running'] = False 

else:
    # å¤±æ•—æ™‚ã®ã¿ã€è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ« '{KNOWLEDGE_BASE_PATH}' ã®å­˜åœ¨ã¨ä¸­èº«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
